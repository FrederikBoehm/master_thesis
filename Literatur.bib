@techreport{turing_whitepaper,
  author      = {NVIDIA},
  title       = {NVIDIA TURING GPU ARCHITECTURE},
  year        = {2018},
  url = {https://images.nvidia.com/aem-dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf},
  urldate = {2022-05-09}
}

@online{pixarxpu,
 author = {Pixar},
 title = {RenderMan XPU: Development Update},
  url = {https://renderman.pixar.com/news/renderman-xpu-development-update},
 urldate = {2022-05-07},
 year = {2018}
}

@book{pbr,
  title={Physically Based Rendering: From Theory to Implementation},
  author={Matt Pharr and Wenzel Jakob and Greg Humphreys},
  isbn={9780128006450},
  year={2004},
  edition={3},
  publisher={Morgan Kaufmann}
}

@article{shannonsampling,
author={Shannon, C.E.},
journal={Proceedings of the IRE}, 
title={Communication in the Presence of Noise}, 
year={1949},
volume={37},
number={1},
pages={10-21},
doi={10.1109/JRPROC.1949.232969},
 }

@book{realtime,
  title={Real-Time Rendering},
  author={Tomas Akenine-Möller and Eric Haines and Naty Hoffman and Angelo Pesce and Michał Iwanicki and Sébastien Hillaire},
  isbn={9781138627000},
  year={2019},
  edition={4},
  publisher={CRC Press}
}

@book{fundamentals,
  title={Fundamentals of Computer Graphics},
  author={Steve Marschner and Peter Shirley},
  isbn={9781482229394},
  year={2015},
  edition={4},
  publisher={CRC Press}
}

@article{sggx,
author = {Heitz, Eric and Dupuy, Jonathan and Crassin, Cyril and Dachsbacher, Carsten},
title = {The SGGX Microflake Distribution},
year = {2015},
issue_date = {August 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/2766988},
doi = {10.1145/2766988},
abstract = {We introduce the Symmetric GGX (SGGX) distribution to represent spatially-varying properties of anisotropic microflake participating media. Our key theoretical insight is to represent a microflake distribution by the projected area of the microflakes. We use the projected area to parameterize the shape of an ellipsoid, from which we recover a distribution of normals. The representation based on the projected area allows for robust linear interpolation and prefiltering, and thanks to its geometric interpretation, we derive closed form expressions for all operations used in the microflake framework. We also incorporate microflakes with diffuse reflectance in our theoretical framework.This allows us to model the appearance of rough diffuse materials in addition to rough specular materials. Finally, we use the idea of sampling the distribution of visible normals to design a perfect importance sampling technique for our SGGX microflake phase functions. It is analytic, deterministic, simple to implement, and one order of magnitude faster than previous work.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {48},
numpages = {11},
keywords = {light transport, microflake theory, global illumination}
}

@inproceedings{microflake,
author = {Jakob, Wenzel and Arbree, Adam and Moon, Jonathan T. and Bala, Kavita and Marschner, Steve},
title = {A Radiative Transfer Framework for Rendering Materials with Anisotropic Structure},
year = {2010},
isbn = {9781450302104},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1833349.1778790},
doi = {10.1145/1833349.1778790},
abstract = {The radiative transfer framework that underlies all current rendering of volumes is limited to scattering media whose properties are invariant to rotation. Many systems allow for "anisotropic scattering," in the sense that scattered intensity depends on the scattering angle, but the standard equation assumes that the structure of the medium is isotropic. This limitation impedes physics-based rendering of volume models of cloth, hair, skin, and other important volumetric or translucent materials that do have anisotropic structure. This paper presents an end-to-end formulation of physics-based volume rendering of anisotropic scattering structures, allowing these materials to become full participants in global illumination simulations.We begin with a generalized radiative transfer equation, derived from scattering by oriented non-spherical particles. Within this framework, we propose a new volume scattering model analogous to the well-known family of microfacet surface reflection models; we derive an anisotropic diffusion approximation, including the weak form required for finite element solution and a way to compute the diffusion matrix from the parameters of the scattering model; and we also derive a new anisotropic dipole BSSRDF for anisotropic translucent materials. We demonstrate results from Monte Carlo, finite element, and dipole simulations. All these contributions are readily implemented in existing rendering systems for volumes and translucent materials, and they all reduce to the standard practice in the isotropic case.},
booktitle = {ACM SIGGRAPH 2010 Papers},
articleno = {53},
numpages = {13},
keywords = {light transport, diffusion theory, finite element method, anisotropy, subsurface scattering, dipole model, BSSRDF},
location = {Los Angeles, California},
series = {SIGGRAPH '10}
}

@inproceedings{ggx,
  author          = {Bruce Walter and Stephen R. Marschner and Hongsong Li and Kenneth E. Torrance},
  title           = {Microfacet Models for Refraction through Rough Surfaces},
  year            = {2007},
  booktitle       = {Proceedings of EGSR 2007},
}

@article{vndf_importance_sampling,
  TITLE = {{Importance Sampling Microfacet-Based BSDFs using the Distribution of Visible Normals}},
  AUTHOR = {Heitz, Eric and D'Eon, Eugene},
  URL = {https://hal.inria.fr/hal-00996995},
  JOURNAL = {{Computer Graphics Forum}},
  PUBLISHER = {{Wiley}},
  YEAR = {2014},
  MONTH = Jun,
  PDF = {https://hal.inria.fr/hal-00996995v1/file/article.pdf},
  HAL_ID = {hal-00996995},
  HAL_VERSION = {v1},
}

@article{hybrid_mesh_volume_lods,
  TITLE = {{Hybrid mesh-volume LoDs for all-scale pre-filtering of complex 3D assets}},
  AUTHOR = {Loubet, Guillaume and Neyret, Fabrice},
  URL = {https://hal.archives-ouvertes.fr/hal-01468817},
  JOURNAL = {{Computer Graphics Forum}},
  PUBLISHER = {{Wiley}},
  VOLUME = {36},
  NUMBER = {2},
  PAGES = {431--442},
  YEAR = {2017},
  DOI = {10.1111/cgf.13138},
  KEYWORDS = {path tracing ; rendering ; LoD ; mesh ; trees ; volume ; hybrid},
  PDF = {https://hal.archives-ouvertes.fr/hal-01468817/file/paper.pdf},
  HAL_ID = {hal-01468817},
  HAL_VERSION = {v1},
}

@Inbook{brick_grid,
author="Hofmann, Nikolai and Evans, Alex",
editor="Marrs, Adam and Shirley, Peter and Wald, Ingo",
title="Efficient Unbiased Volume Path Tracing on the GPU",
bookTitle="Ray Tracing Gems II: Next Generation Real-Time Rendering with DXR, Vulkan, and OptiX",
year="2021",
publisher="Apress",
address="Berkeley, CA",
pages="699--711",
abstract="We present a set of optimizations that improve the performance of high-quality volumetric path tracing. We build upon unbiased volume sampling techniques, i.e., null-collision trackers [16, 8, 15], with voxel data stored in an OpenVDB [14, 13] tree. The presented optimizations achieve an overall 2* to 3* speedup when implemented on a modern GPU, with an approximately 6.5* reduction in memory footprint. The improvements primarily stem from a multi-level digital differential analyzer (DDA) [1, 11, 6] to step through a grid of precomputed bounds; a replacement of the top levels of the OpenVDB tree with a dense indirection texture, similar to virtual textures [3, 4, 17], while preserving some sparsity; and quantization of the voxel data, encoded using GPU-supported block compression. Finally, we examine the isolated effect of our optimizations, covering stochastic filtering, the use of dense indirection textures, compressed voxel data, and singleversus multi-level DDAs.",
isbn="978-1-4842-7185-8",
doi="10.1007/978-1-4842-7185-8_43",
url="https://doi.org/10.1007/978-1-4842-7185-8_43"
}

@article{rendering_equation,
author = {Kajiya, James T.},
title = {The Rendering Equation},
year = {1986},
issue_date = {Aug. 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {4},
issn = {0097-8930},
url = {https://doi.org/10.1145/15886.15902},
doi = {10.1145/15886.15902},
abstract = {We present an integral equation which generalizes a variety of known rendering algorithms. In the course of discussing a monte carlo solution we also present a new form of variance reduction, called Hierarchical sampling and give a number of elaborations shows that it may be an efficient new technique for a wide variety of monte carlo procedures. The resulting rendering algorithm extends the range of optical phenomena which can be effectively simulated.},
journal = {SIGGRAPH Comput. Graph.},
month = {aug},
pages = {143–150},
numpages = {8}
}

@article{novak_overview,
    author = "Novák, Jan and Georgiev, Iliyan and Hanika, Johannes and Jarosz, Wojciech",
    title = "{{Monte}} {{Carlo}} methods for volumetric light transport simulation",
    journal = "Computer Graphics Forum (Proceedings of Eurographics - State of the Art Reports)",
    volume = "37",
    number = "2",
    month = may,
    year = "2018",
    doi = "10/gd2jqq",
    abstract = "The wide adoption of path-tracing algorithms in high-end realistic rendering has stimulated many diverse research initiatives. In this paper we present a coherent survey of methods that utilize Monte Carlo integration for estimating light transport in scenes containing participating media. Our work complements the volume-rendering state-of-the-art report by Cerezo et al. [2005]; we review publications accumulated since its publication over a decade ago, and include earlier methods that are key for building light transport paths in a stochastic manner. We begin by describing analog and non-analog procedures for free-path sampling and discuss various expected-value, collision, and track-length estimators for computing transmittance. We then review the various rendering algorithms that employ these as building blocks for path sampling. Special attention is devoted to null-collision methods that utilize fictitious matter to handle spatially varying densities; we import two “next-flight” estimators originally developed in nuclear sciences. Whenever possible, we draw connections between image-synthesis techniques and methods from particle physics and neutron transport to provide the reader with a broader context."
}

@article{novak_ratio_tracking,
author = {Nov\'{a}k, Jan and Selle, Andrew and Jarosz, Wojciech},
title = {Residual Ratio Tracking for Estimating Attenuation in Participating Media},
year = {2014},
issue_date = {November 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/2661229.2661292},
doi = {10.1145/2661229.2661292},
abstract = {Evaluating transmittance within participating media is a fundamental operation required by many light transport algorithms. We present ratio tracking and residual tracking, two complementary techniques that can be combined into an efficient, unbiased estimator for evaluating transmittance in complex heterogeneous media. In comparison to current approaches, our new estimator is unbiased, yields high efficiency, gracefully handles media with wavelength dependent extinction, and bridges the gap between closed form solutions and purely numerical, unbiased approaches. A key feature of ratio tracking is its ability to handle negative densities. This in turn enables us to separate the main part of the transmittance function, handle it analytically, and numerically estimate only the residual transmittance. In addition to proving the unbiasedness of our estimators, we perform an extensive empirical analysis to reveal parameters that lead to high efficiency. Finally, we describe how to integrate the new techniques into a production path tracer and demonstrate their benefits over traditional unbiased estimators.},
journal = {ACM Trans. Graph.},
month = {nov},
articleno = {179},
numpages = {11},
keywords = {delta tracking, transmittance, participating media}
}

@article{spectral_and_decomposition_tracking,
author = {Kutz, Peter and Habel, Ralf and Li, Yining Karl and Nov\'{a}k, Jan},
title = {Spectral and Decomposition Tracking for Rendering Heterogeneous Volumes},
year = {2017},
issue_date = {August 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3072959.3073665},
doi = {10.1145/3072959.3073665},
abstract = {We present two novel unbiased techniques for sampling free paths in heterogeneous participating media. Our decomposition tracking accelerates free-path construction by splitting the medium into a control component and a residual component and sampling each of them separately. To minimize expensive evaluations of spatially varying collision coefficients, we define the control component to allow constructing free paths in closed form. The residual heterogeneous component is then homogenized by adding a fictitious medium and handled using weighted delta tracking, which removes the need for computing strict bounds of the extinction function. Our second contribution, spectral tracking, enables efficient light transport simulation in chromatic media. We modify free-path distributions to minimize the fluctuation of path throughputs and thereby reduce the estimation variance. To demonstrate the correctness of our algorithms, we derive them directly from the radiative transfer equation by extending the integral formulation of null-collision algorithms recently developed in reactor physics. This mathematical framework, which we thoroughly review, encompasses existing trackers and postulates an entire family of new estimators for solving transport problems; our algorithms are examples of such. We analyze the proposed methods in canonical settings and on production scenes, and compare to the current state of the art in simulating light transport in heterogeneous participating media.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {111},
numpages = {16},
keywords = {free-path sampling, transmittance, participating media, volume rendering, color, delta tracking, ratio tracking}
}

@article{kajiya_rendering_fur_with_textures,
author = {Kajiya, J. T. and Kay, T. L.},
title = {Rendering Fur with Three Dimensional Textures},
year = {1989},
issue_date = {July 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {0097-8930},
url = {https://doi.org/10.1145/74334.74361},
doi = {10.1145/74334.74361},
abstract = {We present a method for rendering scenes with fine detail via an object called a texel, a rendering primitive inspired by volume densities mixed with anisotropic lighting models. This technique solves a long outstanding problem in image synthesis: the rendering of furry surfaces.},
journal = {SIGGRAPH Comput. Graph.},
month = {jul},
pages = {271–280},
numpages = {10}
}

@article{zhao_building_volumetric_appearance_models,
author = {Zhao, Shuang and Jakob, Wenzel and Marschner, Steve and Bala, Kavita},
title = {Building Volumetric Appearance Models of Fabric Using Micro CT Imaging},
year = {2011},
issue_date = {July 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/2010324.1964939},
doi = {10.1145/2010324.1964939},
abstract = {The appearance of complex, thick materials like textiles is determined by their 3D structure, and they are incompletely described by surface reflection models alone. While volume scattering can produce highly realistic images of such materials, creating the required volume density models is difficult. Procedural approaches require significant programmer effort and intuition to design specialpurpose algorithms for each material. Further, the resulting models lack the visual complexity of real materials with their naturally-arising irregularities.This paper proposes a new approach to acquiring volume models, based on density data from X-ray computed tomography (CT) scans and appearance data from photographs under uncontrolled illumination. To model a material, a CT scan is made, resulting in a scalar density volume. This 3D data is processed to extract orientation information and remove noise. The resulting density and orientation fields are used in an appearance matching procedure to define scattering properties in the volume that, when rendered, produce images with texture statistics that match the photographs. As our results show, this approach can easily produce volume appearance models with extreme detail, and at larger scales the distinctive textures and highlights of a range of very different fabrics like satin and velvet emerge automatically---all based simply on having accurate mesoscale geometry.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {44},
numpages = {10},
keywords = {cloth, appearance modeling, volume rendering}
}

@article{meng_multi_scale_modeling_and_rendering_of_granular_materials,
    author = "Meng, Johannes and Papas, Marios and Habel, Ralf and Dachsbacher, Carsten and Marschner, Steve and Gross, Markus and Jarosz, Wojciech",
    title = "Multi-Scale Modeling and Rendering of Granular Materials",
    journal = "ACM Transactions on Graphics (Proceedings of SIGGRAPH)",
    volume = "34",
    number = "4",
    year = "2015",
    month = jul,
    doi = "10/gfzndr",
    keywords = "physically based rendering, granular media, discrete random media",
    abstract = "We address the problem of modeling and rendering granular materials—such as large structures made of sand, snow, or sugar—where an aggregate object is composed of many randomly oriented, but discernible grains. These materials pose a particular challenge as the complex scattering properties of individual grains, and their packing arrangement, can have a dramatic effect on the large-scale appearance of the aggregate object. We propose a multi-scale modeling and rendering framework that adapts to the structure of scattered light at different scales. We rely on path tracing the individual grains only at the finest scale, and—by decoupling individual grains from their arrangement—we develop a modular approach for simulating longer-scale light transport. We model light interactions within and across grains as separate processes and leverage this decomposition to derive parameters for classical radiative transport, including standard volumetric path tracing and a diffusion method that can quickly summarize the large scale transport due to many grain interactions. We require only a one-time precomputation per exemplar grain, which we can then reuse for arbitrary aggregate shapes and a continuum of different packing rates and scales of grains. We demonstrate our method on scenes containing mixtures of tens of millions of individual, complex, specular grains that would be otherwise infeasible to render with standard techniques."
}

@inproceedings{hoppe_simplification,
author = {Hoppe, Hugues},
title = {Progressive Meshes},
year = {1996},
isbn = {0897917464},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/237170.237216},
doi = {10.1145/237170.237216},
booktitle = {Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques},
pages = {99–108},
numpages = {10},
keywords = {mesh simplification, level of detail, progressive transmission, geometry compression, shape interpolation},
series = {SIGGRAPH '96}
}

INPROCEEDINGS{garland_heckbert_simplification,
author={Garland, M. and Heckbert, P.S.},
booktitle={Proceedings Visualization '98 (Cat. No.98CB36276)},
title={Simplifying surfaces with color and texture using quadric error metrics},
year={1998},
volume={},
number={},
pages={263-269},
doi={10.1109/VISUAL.1998.745312}
}

@article{CATMULL1978350,
title = {Recursively generated B-spline surfaces on arbitrary topological meshes},
journal = {Computer-Aided Design},
volume = {10},
number = {6},
pages = {350-355},
year = {1978},
issn = {0010-4485},
doi = {https://doi.org/10.1016/0010-4485(78)90110-0},
url = {https://www.sciencedirect.com/science/article/pii/0010448578901100},
author = {E. Catmull and J. Clark},
abstract = {This paper describes a method for recursively generating surfaces that approximate points lying-on a mesh of arbitrary topology. The method is presented as a generalization of a recursive bicubic B-spline patch subdivision algorithm. For rectangular control-point meshes, the method generates a standard B-spline surface. For non-rectangular meshes, it generates surfaces that are shown to reduce to a standard B-spline surface except at a small number of points, called extraordinary points. Therefore, everywhere except at these points the surface is continuous in tangent and curvature. At the extraordinary points, the pictures of the surface indicate that the surface is at least continuous in tangent, but no proof of continuity is given. A similar algorithm for biquadratic B-splines is also presented.}
}

@online{catmull_clark_step_3,
 author = {UserTwoSix},
  url = {https://renderman.pixar.com/news/renderman-xpu-development-update},
 urldate = {2022-05-13},
 year = {2021}
}

@mastersthesis{loop_subdivision,
  author  = "Charles Loop",
  title   = "Smooth subdivision surfaces based on triangles",
  school  = "University of Utah",
  year    = 1987,
  month   = "August",
  url     = {https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/thesis-10.pdf}
}

@inproceedings{moreton_tessellation,
author = {Moreton, Henry},
title = {Watertight Tessellation Using Forward Differencing},
year = {2001},
isbn = {158113407X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/383507.383520},
doi = {10.1145/383507.383520},
abstract = {In this paper we describe an algorithm and hardware for the tessellation of polynomial surfaces. While conventional forward difference-based tessellation is subject to round off error and cracking, our algorithm produces a bit-for-bit consistent triangle mesh across multiple independently tessellated patches. We present tessellation patterns that exploit the efficiency of iterative evaluation techniques while delivering a defect free adaptive tessellation with continuous level-of-detail. We also report the rendering performance of the resulting physical hardware implementation.},
booktitle = {Proceedings of the ACM SIGGRAPH/EUROGRAPHICS Workshop on Graphics Hardware},
pages = {25–32},
numpages = {8},
keywords = {curves & surfaces, rendering hardware, graphics hardware, geometric modeling, CAD, hardware systems},
location = {Los Angeles, California, USA},
series = {HWWS '01}
}

@article{niessner_tessellation,
	title={Real-time Rendering Techniques with Hardware Tessellation},
	author={Nie{\ss}ner, Matthias and Keinert, Benjamin and Fisher, Matthew and Stamminger, Marc and Loop, Charles and Sch{\"a}fer, Henry},
	journal = {Computer Graphics Forum},
	publisher = {EG},
	volume = {},
	number = {},
	year = {2015},
  url = {http://www.niessnerlab.org/papers/2015/6survey/niessner2015survey.pdf}
}

@article{peng_simplification,
author = {Peng, Chao and Cao, Yong},
title = {A GPU-based Approach for Massive Model Rendering with Frame-to-Frame Coherence},
journal = {Computer Graphics Forum},
volume = {31},
number = {2pt2},
pages = {393-402},
keywords = {I.3.3 Computer Graphics: Picture/Image Generation—Viewing algorithms, I.3.5 Computer Graphics: Computational Geometry and Object Modeling—Geometric algorithms},
doi = {https://doi.org/10.1111/j.1467-8659.2012.03018.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2012.03018.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2012.03018.x},
abstract = {Abstract Rendering massive 3D models in real-time has long been recognized as a very challenging problem because of the limited computational power and memory space available in a workstation. Most existing rendering techniques, especially level of detail (LOD) processing, have suffered from their sequential execution natures. We present a GPU-based approach which enables interactive rendering of large 3D models with hundreds of millions of triangles. Our work contributes to the massive rendering research in two ways. First, we present a simple and efficient mesh simplification algorithm towards GPU architecture. Second, we propose a novel GPU out-of-core approach that adopts a frame-to-frame coherence scheme in order to minimize the high communication cost between CPU and GPU. Our results show that the parallel algorithm of mesh simplification and the GPU out-of-core approach significantly improve the overall rendering performance.},
year = {2012}
}

@article{niessner_subdivision,
  title={Feature-adaptive GPU rendering of Catmull-Clark subdivision surfaces},
  author={Nie{\ss}ner, Matthias and Loop, Charles and Meyer, Mark and Derose, Tony},
  journal={ACM Transactions on Graphics (TOG)},
  volume={31},
  number={1},
  pages={1--11},
  year={2012},
  publisher={ACM New York, NY, USA}
}

@article{afra_voxel_lods,
author = {Áfra, Attila T.},
title = {Interactive Ray Tracing of Large Models Using Voxel Hierarchies},
journal = {Computer Graphics Forum},
volume = {31},
number = {1},
pages = {75-88},
keywords = {ray tracing, massive models, real-time rendering, out-of-core, level-of-detail, voxels,  I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism—Raytracing, I.3.6 Computer Graphics Methodology and Techniques—Graphics data structures and data types},
doi = {https://doi.org/10.1111/j.1467-8659.2011.02085.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2011.02085.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2011.02085.x},
abstract = {Abstract We propose an efficient approach for interactive visualization of massive models with CPU ray tracing. A voxel-based hierarchical level-of-detail (LOD) framework is employed to minimize rendering time and required system memory. In a pre-processing phase, a compressed out-of-core data structure is constructed, which contains the original primitives of the model and the LOD voxels, organized into a kd-tree. During rendering, data is loaded asynchronously to ensure a smooth inspection of the model regardless of the available I/O bandwidth. With our technique, we are able to explore data sets consisting of hundreds of millions of triangles in real-time on a desktop PC with a quad-core CPU.},
year = {2012}
}

@article{yue_space_partitioning,
author = {Yue, Yonghao and Iwasaki, Kei and Chen, Bing-Yu and Dobashi, Yoshinori and Nishita, Tomoyuki},
title = {Toward Optimal Space Partitioning for Unbiased, Adaptive Free Path Sampling of Inhomogeneous Participating Media},
journal = {Computer Graphics Forum},
volume = {30},
number = {7},
pages = {1911-1919},
keywords = {I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism, I.3.3 Computer Graphics: Picture/Image Generation, G.3 Probability and Statistics: Probabilistic Algorithms},
doi = {https://doi.org/10.1111/j.1467-8659.2011.02049.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2011.02049.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2011.02049.x},
abstract = {Abstract Photo-realistic rendering of inhomogeneous participating media with light scattering in consideration is important in computer graphics, and is typically computed using Monte Carlo based methods. The key technique in such methods is the free path sampling, which is used for determining the distance (free path) between successive scattering events. Recently, it has been shown that efficient and unbiased free path sampling methods can be constructed based on Woodcock tracking. The key concept for improving the efficiency is to utilize space partitioning (e.g., kd-tree or uniform grid), and a better space partitioning scheme is important for better sampling efficiency. Thus, an estimation framework for investigating the gain in sampling efficiency is important for determining how to partition the space. However, currently, there is no estimation framework that works in 3D space. In this paper, we propose a new estimation framework to overcome this problem. Using our framework, we can analytically estimate the sampling efficiency for any typical partitioned space. Conversely, we can also use this estimation framework for determining the optimal space partitioning. As an application, we show that new space partitioning schemes can be constructed using our estimation framework. Moreover, we show that the differences in the performances using different schemes can be predicted fairly well using our estimation framework.},
year = {2011}
}

@article{museth_vdb,
  title={VDB: High-resolution sparse volumes with dynamic topology},
  author={Museth, Ken},
  journal={ACM transactions on graphics (TOG)},
  volume={32},
  number={3},
  pages={1--22},
  year={2013},
  publisher={ACM New York, NY, USA}
}

@book{lambert,
  title={Photometria sive de mensura et gradibus luminis, colorum et umbrae},
  author={Lambert, Johann Heinrich},
  year={1760},
  publisher={sumptibus vidvae E. Klett, typis CP Detleffsen}
}

@article{perlin_hypertexture,
author = {Perlin, K. and Hoffert, E. M.},
title = {Hypertexture},
year = {1989},
issue_date = {July 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {0097-8930},
url = {https://doi.org/10.1145/74334.74359},
doi = {10.1145/74334.74359},
abstract = {We model phenomena intermediate between shape and texture by using space-filling applicative functions to modulate density. The model is essentially an extension of procedural solid texture synthesis, but evaluated throughout a volumetric region instead of only at surfaces.We have been able to obtain visually realistic representations of such shape+texture (hypertexture) phenomena as hair, fur, fire, glass, fluid flow and erosion effects. We show how this is done, first by describing a set of base level functions to provide basic texture and control capability, then by combining these to synthesize various phenomena.Hypertexture exists within an intermediate region between object and not-object. We introduce a notion of generalized boolean shape operators to combine shapes having such a region.Rendering is accomplished by ray marching from the eye point through the volume to accumulate opacity along each ray. We have implemented our hypertexture rendering algorithms on a traditional serial computer, a distributed network of computers and a coarse-grain MIMD computer. Extensions to the rendering technique incorporating refraction and reflection effects are discussed.},
journal = {SIGGRAPH Comput. Graph.},
month = {jul},
pages = {253–262},
numpages = {10}
}

@techreport{sutton_regular_tracking,
  title={The physical models and statistical procedures used in the RACER Monte Carlo code},
  author={Sutton, TM and Brown, FB and Bischoff, FG and MacMillan, DB and Ellis, CL and Ward, JT and Ballinger, CT and Kelly, DJ and Schindler, L},
  year={1999},
  institution={Knolls Atomic Power Lab.}
}

@inproceedings{woodcock,
  title={Techniques used in the GEM code for Monte Carlo neutronics calculations in reactors and other systems of complex geometry},
  author={Woodcock, E and Murphy, T and Hemmings, P and Longworth, S},
  booktitle={Proc. Conf. Applications of Computing Methods to Reactor Problems},
  volume={557},
  number={2},
  year={1965}
}





